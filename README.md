# ğŸš€ Kasparro â€” Agentic Facebook Performance Analyst

An autonomous multi-agent system that diagnoses Facebook Ads performance, identifies ROAS fluctuation drivers, and recommends data-driven creative improvements.

[![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python&logoColor=white)](https://www.python.org/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4-00A67E?logo=openai&logoColor=white)](https://openai.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Version](https://img.shields.io/badge/Version-v1.0-orange)](https://github.com/PVK-Nandan/kasparro-agentic-fb-analyst-nandan/releases/tag/v1.0)

---

## âš¡ Quick Start

```bash
# Check Python version (requires >= 3.10)
python -V

# Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set your OpenAI API key
export OPENAI_API_KEY="your-key-here"  # Windows: set OPENAI_API_KEY=your-key-here

# Run the system
python src/run.py "Analyze ROAS drop in last 7 days"
```

---

## ğŸ”¥ Features

| Capability | Description |
|------------|-------------|
| ğŸ“Š **Data Agent** | Ingests CSV â†’ cleans â†’ aggregates â†’ summarizes metrics (ROAS, CTR, CPC, Spend) |
| ğŸ§  **Insight Agent** | Generates hypotheses from statistics & trends |
| âœ” **Evaluator Agent** | Validates claims, assigns confidence score (0-1), retries if weak |
| âœ **Creative Generator** | Suggests new high-impact creatives based on winners/losers |
| ğŸ”„ **Fully Orchestrated Pipeline** | Query â†’ Planning â†’ Data â†’ Insights â†’ Evaluation â†’ Creatives |
| ğŸ§¾ **JSON + Markdown Output** | Reports saved with explanations, evidence, recommendations |
| ğŸ“œ **Logging + Observability** | Every run produces trace logs for debugging & audits |

---

## ğŸ“Š Data Setup

Place your Facebook Ads CSV file in one of two ways:

**Option 1: Full dataset**
```bash
export DATA_CSV=/path/to/synthetic_fb_ads_undergarments.csv
```

**Option 2: Use sample data**
```bash
# Copy sample data (included in repo)
cp data/sample_fb_ads.csv data/fb_ads.csv
# Edit config/config.yaml to set use_sample_data: true
```

See `data/README.md` for data format details.

---

## âš™ï¸ Configuration

Edit `config/config.yaml`:

```yaml
python: "3.10"
random_seed: 42
confidence_min: 0.6
use_sample_data: true
data_path: "data/sample_fb_ads.csv"
openai_model: "gpt-4"
max_insights: 5
```

---

## ğŸ“‚ Project Structure

```
kasparro-agentic-fb-analyst-nandan/
â”œâ”€â”€ README.md                          ğŸ“˜ Main documentation + usage guide
â”œâ”€â”€ requirements.txt                   ğŸ“¦ Dependency list (pinned)
â”œâ”€â”€ Makefile                           âš™ï¸ Quick automation tasks
â”œâ”€â”€ .gitignore                         ğŸš« Prevents sensitive/unnecessary files
â”œâ”€â”€ agent_graph.md                     ğŸ§  System architecture layout
â”œâ”€â”€ SELF_REVIEW.md                     ğŸ” Deep design reasoning + decisions
â”œâ”€â”€ SETUP_GUIDE.md                     ğŸš€ Setup & execution instructions
â”œâ”€â”€ SUBMISSION_SUMMARY.md              ğŸ Final solution overview
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                    ğŸ”§ All runtime configuration + model settings
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ run.py                         â–¶ Entry point â€” run analysis here
â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”‚   â””â”€â”€ agent_orchestrator.py      ğŸ¤– Multi-agent execution controller
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ planner.py                 ğŸ§­ Breaks query into subtasks
â”‚   â”‚   â”œâ”€â”€ data_agent.py              ğŸ“Š CSV ingestion + metric summaries
â”‚   â”‚   â”œâ”€â”€ insight_agent.py           ğŸ§  Hypothesis generation
â”‚   â”‚   â”œâ”€â”€ evaluator.py               ğŸ§¾ Confidence-based validation
â”‚   â”‚   â””â”€â”€ creative_generator.py      âœ AI-powered creative suggestions
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ helpers.py                 ğŸ›  Shared utilities + logging support
â”‚
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ planner_prompt.md              ğŸ§© Task planning instructions
â”‚   â”œâ”€â”€ data_agent_prompt.md           ğŸ”¢ Data summarization schema
â”‚   â”œâ”€â”€ insight_agent_prompt.md        ğŸ” Insight reasoning framework
â”‚   â”œâ”€â”€ evaluator_prompt.md            ğŸ§  Confidence scoring + validation
â”‚   â””â”€â”€ creative_generator_prompt.md   ğŸ¨ Ad copy + creative direction
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ README.md                      ğŸ“„ Data specification + schema
â”‚   â””â”€â”€ sample_fb_ads.csv              ğŸ§ª Example dataset for testing
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_evaluator.py              ğŸ§ª Unit tests for evaluator logic
â”‚
â”œâ”€â”€ reports/                           ğŸ“¤ Final analysis output (generated)
â””â”€â”€ logs/                              ğŸ“‘ Trace logs for execution debugging
```

---

## ğŸ—ï¸ Architecture

### Agent Flow Diagram

```
User Query
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Planner Agent   â”‚ â†’ Decomposes query into subtasks
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Agent      â”‚ â†’ Loads & summarizes dataset
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Insight Agent   â”‚ â†’ Generates hypotheses
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Evaluator Agent â”‚ â†’ Validates with quantitative analysis
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   (Feedback loop: retry low-confidence)
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Creative Gen    â”‚ â†’ Produces creative recommendations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Final Report
```

### Agent Responsibilities

1. **Planner**: Breaks user queries into structured subtasks (e.g., "identify ROAS drivers", "recommend creatives")
2. **Data Agent**: Loads CSV, computes key metrics, generates statistical summaries
3. **Insight Agent**: Forms hypotheses about performance patterns (audience fatigue, creative decay, etc.)
4. **Evaluator**: Validates hypotheses with quantitative checks, assigns confidence scores
5. **Creative Generator**: Produces new headlines/messages for low-CTR campaigns based on existing data

---

## ğŸ’» Running Examples

```bash
# Analyze ROAS changes
python src/run.py "Why did ROAS drop in the last 7 days?"

# Find low-performing campaigns
python src/run.py "Which campaigns have CTR below 1.5%?"

# Get creative recommendations
python src/run.py "Suggest new creative messages for low-performing ads"

# Complex analysis
python src/run.py "Analyze performance by platform and recommend optimizations"
```

---

## ğŸ“¤ Outputs

All outputs are generated in `reports/`:

- **report.md**: Human-readable markdown summary
- **insights.json**: Structured hypotheses with confidence scores
- **creatives.json**: Creative recommendations for low-CTR campaigns

---

## ğŸ§ª Validation & Testing

The system includes quantitative validation:

```bash
# Run evaluator tests
python -m pytest tests/test_evaluator.py

# Check logs for trace evidence
cat logs/execution_trace_*.json
```

---

## ğŸ“Š Observability

Execution traces are logged in `logs/` directory with:
- Agent inputs/outputs
- Confidence scores
- Validation results
- Timestamp information

---

## ğŸ¯ Key Design Decisions

### Prompt Architecture
- **Structured prompts** with explicit reasoning steps (Think â†’ Analyze â†’ Conclude)
- **JSON schemas** for consistent output parsing
- **Reflection loops** for low-confidence results

### Data Handling
- **Summarization over raw data**: Agents receive statistical summaries, not full CSVs
- **Missing data handling**: Graceful degradation when fields are null
- **Date-aware analysis**: Proper time-series grouping for trend detection

### Confidence Scoring
- Evaluator assigns 0-1 confidence to each hypothesis
- Hypotheses below threshold trigger re-analysis
- Final report includes only high-confidence insights

---

## ğŸ“‹ Requirements

- Python 3.10+
- OpenAI API key
- Dependencies in `requirements.txt`

---

## ğŸ“ Why This Project Matters

This system demonstrates true applied AI engineering, not prompt hacking.

âœ” Real software architecture  
âœ” Confidence-based validation  
âœ” Separate reasoning vs creativity modules  
âœ” Scalable agent design  
âœ” Logs, traceability, maintainability  

This is the type of pipeline you would use in production, not a hackathon demo.

---

## ğŸ“Œ Release Information

- **Version**: v1.0
- **Release Tag**: `v1.0`
- **Status**: Stable

---

## ğŸ‘¨â€ğŸ’» About the Developer

**Nandan Pakki V K**

ğŸ§  AI/ML Engineer | Autonomous Agent Systems Specialist

Building production-grade AI solutions with real-world impact

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/nandan-pakki-v-k-01639b253/)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/PVK-Nandan)
[![Email](https://img.shields.io/badge/Email-Contact-D14836?style=for-the-badge&logo=gmail&logoColor=white)](mailto:grandmaster@kasparro.com)

**ğŸ’¡ Specializations:**  
Multi-Agent Systems â€¢ LangGraph â€¢ OpenAI â€¢ RAG Pipelines â€¢ Production ML

**ğŸ”¬ Currently Working On:**  
Autonomous AI agents for marketing analytics and business intelligence

---

â­ **If you found this project helpful, please consider giving it a star!**

Built with ğŸ’™ by [Nandan Pakki V K](https://github.com/PVK-Nandan)
